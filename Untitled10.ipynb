{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP9/L2/ufPKbRfhDZaVKAtT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodeWithJatin1/Celebal_project/blob/main/Untitled10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from scipy.stats import uniform, randint\n",
        "\n",
        "iris = load_iris()\n",
        "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "y = iris.target\n",
        "\n",
        "print(\"Dataset Loaded:\")\n",
        "print(f\"Features (X) shape: {X.shape}\")\n",
        "print(f\"Target (y) shape: {y.shape}\\n\")\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Dataset Split:\")\n",
        "print(f\"Training features (X_train) shape: {X_train.shape}\")\n",
        "print(f\"Testing features (X_test) shape: {X_test.shape}\\n\")\n",
        "\n",
        "model_results = {}\n",
        "\n",
        "models = {\n",
        "    \"Logistic Regression (Base)\": LogisticRegression(max_iter=500, random_state=42),\n",
        "    \"Random Forest (Base)\": RandomForestClassifier(random_state=42),\n",
        "    \"Support Vector Machine (Base)\": SVC(random_state=42)\n",
        "}\n",
        "\n",
        "print(\"ðŸ”Ž Base Model Evaluation:\")\n",
        "for name, model in models.items():\n",
        "    print(f\"\\n--- Training and Evaluating: {name} ---\")\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "    recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "\n",
        "    print(f\"Accuracy : {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall   : {recall:.4f}\")\n",
        "    print(f\"F1 Score : {f1:.4f}\")\n",
        "\n",
        "    model_results[name] = {\n",
        "        'model': model,\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1_score': f1,\n",
        "        'tuned': False\n",
        "    }\n",
        "\n",
        "print(\"\\n--- Hyperparameter Tuning: GridSearchCV for Random Forest ---\")\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [10, 50, 100, 200],\n",
        "    'max_depth': [None, 5, 10, 15],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "grid_search_rf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_rf, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "grid_search_rf.fit(X_train, y_train)\n",
        "\n",
        "best_rf_grid = grid_search_rf.best_estimator_\n",
        "y_pred_best_rf_grid = best_rf_grid.predict(X_test)\n",
        "\n",
        "print(\"\\nâœ… Best Model after GridSearchCV (Random Forest):\")\n",
        "print(\"Best Parameters:\", grid_search_rf.best_params_)\n",
        "\n",
        "accuracy_rf_grid = accuracy_score(y_test, y_pred_best_rf_grid)\n",
        "precision_rf_grid = precision_score(y_test, y_pred_best_rf_grid, average='weighted', zero_division=0)\n",
        "recall_rf_grid = recall_score(y_test, y_pred_best_rf_grid, average='weighted', zero_division=0)\n",
        "f1_rf_grid = f1_score(y_test, y_pred_best_rf_grid, average='weighted', zero_division=0)\n",
        "\n",
        "print(f\"Accuracy : {accuracy_rf_grid:.4f}\")\n",
        "print(f\"Precision: {precision_rf_grid:.4f}\")\n",
        "print(f\"Recall   : {recall_rf_grid:.4f}\")\n",
        "print(f\"F1 Score : {f1_rf_grid:.4f}\")\n",
        "\n",
        "model_results[\"Random Forest (GridSearchCV)\"] = {\n",
        "    'model': best_rf_grid,\n",
        "    'accuracy': accuracy_rf_grid,\n",
        "    'precision': precision_rf_grid,\n",
        "    'recall': recall_rf_grid,\n",
        "    'f1_score': f1_rf_grid,\n",
        "    'tuned': True,\n",
        "    'tuning_method': 'GridSearchCV'\n",
        "}\n",
        "\n",
        "print(\"\\n--- Hyperparameter Tuning: RandomizedSearchCV for Logistic Regression ---\")\n",
        "\n",
        "param_distributions_lr = {\n",
        "    'C': uniform(loc=0.01, scale=100),\n",
        "    'solver': ['liblinear', 'lbfgs', 'saga'],\n",
        "    'penalty': ['l1', 'l2']\n",
        "}\n",
        "\n",
        "random_search_lr = RandomizedSearchCV(\n",
        "    LogisticRegression(max_iter=1000, random_state=42),\n",
        "    param_distributions=param_distributions_lr,\n",
        "    n_iter=50,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    error_score='raise'\n",
        ")\n",
        "\n",
        "try:\n",
        "    random_search_lr.fit(X_train, y_train)\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred during RandomizedSearchCV for Logistic Regression: {e}\")\n",
        "    print(\"Some solver/penalty combinations might be incompatible. Retrying with a more robust parameter distribution.\")\n",
        "    param_distributions_lr = {\n",
        "        'C': uniform(loc=0.01, scale=100),\n",
        "        'solver': ['liblinear', 'lbfgs'],\n",
        "        'penalty': ['l2']\n",
        "    }\n",
        "    random_search_lr = RandomizedSearchCV(\n",
        "        LogisticRegression(max_iter=1000, random_state=42),\n",
        "        param_distributions=param_distributions_lr,\n",
        "        n_iter=50,\n",
        "        cv=5,\n",
        "        scoring='accuracy',\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    random_search_lr.fit(X_train, y_train)\n",
        "\n",
        "best_lr_random = random_search_lr.best_estimator_\n",
        "y_pred_best_lr_random = best_lr_random.predict(X_test)\n",
        "\n",
        "print(\"\\nâœ… Best Model after RandomizedSearchCV (Logistic Regression):\")\n",
        "print(\"Best Parameters:\", random_search_lr.best_params_)\n",
        "\n",
        "accuracy_lr_random = accuracy_score(y_test, y_pred_best_lr_random)\n",
        "precision_lr_random = precision_score(y_test, y_pred_best_lr_random, average='weighted', zero_division=0)\n",
        "recall_lr_random = recall_score(y_test, y_pred_best_lr_random, average='weighted', zero_division=0)\n",
        "f1_lr_random = f1_score(y_test, y_pred_best_lr_random, average='weighted', zero_division=0)\n",
        "\n",
        "print(f\"Accuracy : {accuracy_lr_random:.4f}\")\n",
        "print(f\"Precision: {precision_lr_random:.4f}\")\n",
        "print(f\"Recall   : {recall_lr_random:.4f}\")\n",
        "print(f\"F1 Score : {f1_lr_random:.4f}\")\n",
        "\n",
        "model_results[\"Logistic Regression (RandomizedSearchCV)\"] = {\n",
        "    'model': best_lr_random,\n",
        "    'accuracy': accuracy_lr_random,\n",
        "    'precision': precision_lr_random,\n",
        "    'recall': recall_lr_random,\n",
        "    'f1_score': f1_lr_random,\n",
        "    'tuned': True,\n",
        "    'tuning_method': 'RandomizedSearchCV'\n",
        "}\n",
        "\n",
        "print(\"\\n--- Comprehensive Model Performance Summary ---\")\n",
        "print(\"{:<40} {:<10} {:<10} {:<10} {:<10}\".format(\"Model Name\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"))\n",
        "print(\"-\" * 90)\n",
        "\n",
        "best_overall_model_name = \"\"\n",
        "best_overall_accuracy = -1\n",
        "\n",
        "for name, metrics in model_results.items():\n",
        "    print(\"{:<40} {:<10.4f} {:<10.4f} {:<10.4f} {:<10.4f}\".format(\n",
        "        name,\n",
        "        metrics['accuracy'],\n",
        "        metrics['precision'],\n",
        "        metrics['recall'],\n",
        "        metrics['f1_score']\n",
        "    ))\n",
        "    if metrics['accuracy'] > best_overall_accuracy:\n",
        "        best_overall_accuracy = metrics['accuracy']\n",
        "        best_overall_model_name = name\n",
        "\n",
        "print(\"\\n--- Best Performing Model Overall ---\")\n",
        "print(f\"The best performing model based on Accuracy is: {best_overall_model_name}\")\n",
        "print(f\"With an Accuracy of: {best_overall_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiSbnQ8_CTHV",
        "outputId": "a9268a71-f977-4346-d85d-ea0fa7f38c90"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Loaded:\n",
            "Features (X) shape: (150, 4)\n",
            "Target (y) shape: (150,)\n",
            "\n",
            "Dataset Split:\n",
            "Training features (X_train) shape: (120, 4)\n",
            "Testing features (X_test) shape: (30, 4)\n",
            "\n",
            "ðŸ”Ž Base Model Evaluation:\n",
            "\n",
            "--- Training and Evaluating: Logistic Regression (Base) ---\n",
            "Accuracy : 1.0000\n",
            "Precision: 1.0000\n",
            "Recall   : 1.0000\n",
            "F1 Score : 1.0000\n",
            "\n",
            "--- Training and Evaluating: Random Forest (Base) ---\n",
            "Accuracy : 1.0000\n",
            "Precision: 1.0000\n",
            "Recall   : 1.0000\n",
            "F1 Score : 1.0000\n",
            "\n",
            "--- Training and Evaluating: Support Vector Machine (Base) ---\n",
            "Accuracy : 1.0000\n",
            "Precision: 1.0000\n",
            "Recall   : 1.0000\n",
            "F1 Score : 1.0000\n",
            "\n",
            "--- Hyperparameter Tuning: GridSearchCV for Random Forest ---\n",
            "\n",
            "âœ… Best Model after GridSearchCV (Random Forest):\n",
            "Best Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 10}\n",
            "Accuracy : 1.0000\n",
            "Precision: 1.0000\n",
            "Recall   : 1.0000\n",
            "F1 Score : 1.0000\n",
            "\n",
            "--- Hyperparameter Tuning: RandomizedSearchCV for Logistic Regression ---\n",
            "An error occurred during RandomizedSearchCV for Logistic Regression: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
            "Some solver/penalty combinations might be incompatible. Retrying with a more robust parameter distribution.\n",
            "\n",
            "âœ… Best Model after RandomizedSearchCV (Logistic Regression):\n",
            "Best Parameters: {'C': np.float64(37.464011884736244), 'penalty': 'l2', 'solver': 'liblinear'}\n",
            "Accuracy : 1.0000\n",
            "Precision: 1.0000\n",
            "Recall   : 1.0000\n",
            "F1 Score : 1.0000\n",
            "\n",
            "--- Comprehensive Model Performance Summary ---\n",
            "Model Name                               Accuracy   Precision  Recall     F1 Score  \n",
            "------------------------------------------------------------------------------------------\n",
            "Logistic Regression (Base)               1.0000     1.0000     1.0000     1.0000    \n",
            "Random Forest (Base)                     1.0000     1.0000     1.0000     1.0000    \n",
            "Support Vector Machine (Base)            1.0000     1.0000     1.0000     1.0000    \n",
            "Random Forest (GridSearchCV)             1.0000     1.0000     1.0000     1.0000    \n",
            "Logistic Regression (RandomizedSearchCV) 1.0000     1.0000     1.0000     1.0000    \n",
            "\n",
            "--- Best Performing Model Overall ---\n",
            "The best performing model based on Accuracy is: Logistic Regression (Base)\n",
            "With an Accuracy of: 1.0000\n"
          ]
        }
      ]
    }
  ]
}